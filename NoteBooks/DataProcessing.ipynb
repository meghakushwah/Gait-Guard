{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found folder: ../Datasets/Video_DATASET\\Normal\n",
      "‚úÖ Found folder: ../Datasets/Video_DATASET\\Limping\n",
      "‚úÖ Found folder: ../Datasets/Video_DATASET\\Slouch\n",
      "‚úÖ Found folder: ../Datasets/Video_DATASET\\No_arm_swing\n",
      "‚úÖ Found folder: ../Datasets/Video_DATASET\\Circumduction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = r\"../Datasets/Video_DATASET\"\n",
    "\n",
    "dataset_categories = {\n",
    "    \"Normal\": 0,\n",
    "    \"Limping\": 1,\n",
    "    \"Slouch\": 2,\n",
    "    \"No_arm_swing\": 3,\n",
    "    \"Circumduction\": 4\n",
    "}\n",
    "\n",
    "for category, label in dataset_categories.items():\n",
    "    folder_path = os.path.join(BASE_DIR, category)\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"‚úÖ Found folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Folder not found: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:13<00:00,  2.67s/it]\n",
      "Processing 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:19<00:00,  2.81s/it]\n",
      "Processing 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:10<00:00,  2.75s/it]\n",
      "Processing 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:09<00:00,  3.23s/it]\n",
      "Processing 4:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:08<00:08,  2.74s/it]"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Function to extract pose keypoints from a video\n",
    "def extract_keypoints_from_video(video_path, max_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_sequence = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error: Could not open {video_path}\")\n",
    "        return None\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count >= max_frames:\n",
    "            break\n",
    "\n",
    "        # Convert to RGB and process with MediaPipe Pose\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            row = []  # No frame number included\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                # Store normalized keypoints (x, y, z, visibility)\n",
    "                row.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "\n",
    "            keypoints_sequence.append(row)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    if len(keypoints_sequence) > 0:\n",
    "        return np.array(keypoints_sequence)  # Shape: (frames, 132)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to process all videos in a dataset category\n",
    "def process_videos(video_folder, label, max_videos=None):\n",
    "    data = []\n",
    "    labels = []\n",
    "    video_files = os.listdir(video_folder)\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    for video_file in tqdm(video_files, desc=f\"Processing {label}\"):\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "        keypoints = extract_keypoints_from_video(video_path)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            for frame_data in keypoints:\n",
    "                data.append(frame_data)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Define dataset categories and process videos\n",
    "dataset_categories = {\n",
    "    \"Normal\": 0,\n",
    "    \"Limping\": 1,\n",
    "    \"Slouch\": 2,\n",
    "    \"No_arm_swing\": 3,\n",
    "    \"Circumduction\": 4\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for category, label in dataset_categories.items():\n",
    "    folder_path = f\"../Datasets/Video_DATASET/{category}\"\n",
    "    if os.path.exists(folder_path):\n",
    "        data, labels = process_videos(folder_path, label)\n",
    "        all_data.extend(data)\n",
    "        all_labels.extend(labels)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: Folder {folder_path} not found.\")\n",
    "\n",
    "# Convert to DataFrame and save as CSV (excluding \"Frame\" column)\n",
    "if all_data:\n",
    "    columns = [f\"K{i}_{c}\" for i in range(33) for c in (\"x\", \"y\", \"z\", \"visibility\")] + [\"label\"]\n",
    "    df = pd.DataFrame(all_data, columns=columns[:-1])  # Exclude Label column temporarily\n",
    "    df[\"label\"] = all_labels  # Add label column separately\n",
    "    df.to_csv(\"../Datasets/CSV_DATASET/gait_keypoints.csv\", index=False)\n",
    "    print(\"üìÇ Keypoints saved to gait_keypoints.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
